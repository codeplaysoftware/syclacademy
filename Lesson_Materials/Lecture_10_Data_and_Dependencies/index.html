<!DOCTYPE html>

<html>
	<head>
	    <meta charset="utf-8">
		<link rel="stylesheet" href="../common-revealjs/css/reveal.css">
		<link rel="stylesheet" href="../common-revealjs/css/theme/white.css">
		<link rel="stylesheet" href="../common-revealjs/css/custom.css">
		<script>
			// This is needed when printing the slides to pdf
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
		<script>
		    // This is used to display the static images on each slide,
			// See global-images in this html file and custom.css
			(function() {
				if(window.addEventListener) {
					window.addEventListener('load', () => {
						let slides = document.getElementsByClassName("slide-background");

						if (slides.length === 0) {
							slides = document.getElementsByClassName("pdf-page")
						}

						// Insert global images on each slide
						for(let i = 0, max = slides.length; i < max; i++) {
							let cln = document.getElementById("global-images").cloneNode(true);
							cln.removeAttribute("id");
							slides[i].appendChild(cln);
						}

						// Remove top level global images
						let elem = document.getElementById("global-images");
						elem.parentElement.removeChild(elem);
					}, false);
				}
			})();
		</script>
		
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<div id="global-images" class="global-images">
					<img src="../common-revealjs/images/sycl_academy.png" />
					<img src="../common-revealjs/images/sycl_logo.png" />
					<img src="../common-revealjs/images/trademarks.png" />
					<img src="../common-revealjs/images/codeplay.png" />
				</div>
				<!--Slide 1-->
				<section class="hbox">
					<div class="hbox" data-markdown>
						## Data and Dependencies
					</div>
				</section>
				<!--Slide 2-->
				<section class="hbox" data-markdown>
					## Learning Objectives
					* Learn about how to create dependencies between kernel functions
					* Learn about how to move data between the host and device(s)
					* Learn about the differences between the buffer/accessor and USM data management models
					* Learn how to represent basic data flow graphs
                </section>
				<!--Slide 3-->
				<section>
					<div class="hbox" data-markdown>
						#### Access/buffer and USM
					</div>
					<div class="container" data-markdown>
						There are two ways to move data and create dependencies between kernel functions in SYCL
					</div>
					<div class="container">
						<div class="col" data-markdown>
							Buffer/accessor data movement model
							<br/>
							* Data dependencies analysis
							* Implicit data movement
						</div>
						<div class="col" data-markdown>
							USM data movement model
							<br/>
							* Manual chaining of dependencies
							* Explicit data movement
						</div>
					</div>
				</section>
				<!--Slide 4-->
				<section>
					<div class="hbox" data-markdown>
						#### Creating dependencies
					</div>
					<div class="container">
						<div class="col" data-markdown>
							![SYCL](./data_dependency.png "SYCL")
						</div>
						<div class="col" data-markdown>
							* Kernel A first writes to the data.
							* Kernel B then reads from and writes to the data.
							* This creates a read-after-write (RAW) relationship.
							* There must be a dependency created between Kernel A and Kernel B.
						</div>
					</div>
				</section>
				<!--Slide 5-->
				<section>
					<div class="hbox" data-markdown>
						#### Moving data
					</div>
					<div class="container">
						<div class="col" data-markdown>
							![SYCL](./data_movement.png "SYCL")
						</div>
						<div class="col" data-markdown>
							* Here both kernel functions are enqueued to the same device, in this case a GPU.
							* The data must be copied to the GPU before the Kernel A is executed.
							* The data must remain on the GPU for Kernel B to be executed.
							* The data must be copied back to the host after Kernel B has executed.
						</div>
					</div>
				</section>
				<!--Slide 6-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow
					</div>
					<div class="container">
						<div class="col" data-markdown>
							![SYCL](./data_flow.png "SYCL")
						</div>
						<div class="col" data-markdown>
							* Combining kernel function dependencies and the data movement dependencies we have a final data flow graph.
							* This graph defines the order in which all commands must execute in order to maintain consistency.
							* In more complex data flow graphs there may be multiple orderings which can achieve the same consistency.
						</div>
					</div>
				</section>
				<!--Slide 7-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow with buffers and accessors
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
buf = sycl::buffer(data, sycl::range{1024});

gpuQueue.submit([&](sycl::handler &cgh){
  auto acc = buf.get_access(cgh);
      
  cgh.parallel_for&lt;kernel_a&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.submit([&](sycl::handler &cgh){
  auto acc = buf.get_access(cgh);
		
  cgh.parallel_for&lt;kernel_b&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.wait();
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* The buffer/accessor data management model data model is descriptive.
							* Dependencies and data movement is inferred from the access requirements of command groups.
							* The SYCL runtime is responsible for guaranteeing that data dependencies and consistency are maintained.
						</div>
					</div>
				</section>
				<!--Slide 8-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow with buffers and accessors
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
<mark>buf = sycl::buffer(data, sycl::range{1024});</mark>

gpuQueue.submit([&](sycl::handler &cgh){
  auto acc = buf.get_access(cgh);
      
  cgh.parallel_for&lt;kernel_a&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.submit([&](sycl::handler &cgh){
  auto acc = buf.get_access(cgh);
		
  cgh.parallel_for&lt;kernel_b&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.wait();
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* A `buffer` object is responsible for managing data between the host and one or more devices.
							* It is also responsible for tracking dependencies on the data is manages.
							* It will also allocating memory and move data when necessary.
							* Note that a `buffer` is lazy and will not allocate or move data until it is asked to.
						</div>
					</div>
				</section>
				<!--Slide 9-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow with buffers and accessors
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
buf = sycl::buffer(data, sycl::range{1024});

gpuQueue.submit([&](sycl::handler &cgh){
  <mark>auto acc = buf.get_access(cgh);</mark>
	  
  cgh.parallel_for&lt;my_kernel&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.submit([&](sycl::handler &cgh){
  <mark>auto acc = buf.get_access(cgh);</mark>
		
  cgh.parallel_for&lt;my_kernel&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.wait();
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* An `accessor` object is responsible for describing data access requirements.
							* It describes what data a kernel function is accessing and how it is accessing it.
							* The `buffer` object uses this information to create infer dependencies and data movement.
						</div>
					</div>
				</section>
				<!--Slide 10-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow with buffers and accessors
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
buf = sycl::buffer(data, sycl::range{1024});

gpuQueue.submit([&](sycl::handler &cgh){
  auto acc = buf.get_access(<mark>cgh</mark>);
	  
  cgh.parallel_for&lt;my_kernel&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.submit([&](sycl::handler &cgh){
  auto acc = buf.get_access(<mark>cgh</mark>);
		
  cgh.parallel_for&lt;my_kernel&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
    acc[idx] = /* some computation */
  });
});

gpuQueue.wait();
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* Associating the `accessor` object with the `handler` connects the access dependency to the kernel function.
							* It also associates the access requirement with the device being targeted.
						</div>
					</div>
				</section>
				<!--Slide 11-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow with USM
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
auto devicePtr   = usm_wrapper&lt;int&gt;(
  malloc_device&lt;int&gt;(1024, gpuQueue));
  
auto e1 = gpuQueue.memcpy(devicePtr, data, sizeof(int));
  
auto e2 = gpuQueue.parallel_for&lt;kernel_a&gt;(
  sycl::range{1024}, e1, [=](sycl::id&lt;1&gt; idx){
    devicePtr[idx] = /* some computation */
});

auto e3 = gpuQueue.parallel_for&lt;kernel_b&gt;(
  sycl::range{1024}, e2, [=](sycl::id&lt;1&gt; idx){
    devicePtr[idx] = /* some computation */
});

auto e4 = gpuQueue.memcpy(data, devicePtr, sizeof(int),
  e3);

e4.wait();
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* The USM data management model data model is prescriptive.
							* Dependencies are defined explicitly by passing around `event` objects.
							* Data movement is performed explicitly by enqueuing `memcpy` operations.
							* The user is responsible for ensuring data dependencies and consistency are maintained.
						</div>
					</div>
				</section>
				<!--Slide 12-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow with USM
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
auto devicePtr   = usm_wrapper&lt;int&gt;(
  malloc_device&lt;int&gt;(1024, gpuQueue));
  
<mark>auto e1</mark> = gpuQueue.memcpy(devicePtr, data, sizeof(int));
  
<mark>auto e2</mark> = gpuQueue.parallel_for&lt;kernel_a&gt;(
  sycl::range{1024}, <mark>e1</mark>, [=](sycl::id&lt;1&gt; idx){
    devicePtr[idx] = /* some computation */
});

<mark>auto e3</mark> = gpuQueue.parallel_for&lt;kernel_b&gt;(
  sycl::range{1024}, <mark>e2</mark>, [=](sycl::id&lt;1&gt; idx){
    devicePtr[idx] = /* some computation */
});

<mark>auto e4</mark> = gpuQueue..memcpy(data, devicePtr, sizeof(int),
  <mark>e3</mark>);

<mark>e4.wait();</mark>
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* Each command enqueued to the `queue` produces an `event` object which can be used to synchronize with the completion of that command.
							* Passing those `event` objects when enqueueing other commands creates dependencies.
							* Note that `memcpy` doesn't have an overload which takes an `event` so you have to create a command group and call `depends_on` to create a dependency.
						</div>
					</div>
				</section>
				<!--Slide 13-->
				<section>
					<div class="hbox" data-markdown>
						#### Data flow with USM
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
auto devicePtr   = usm_wrapper&lt;int&gt;(
  malloc_device&lt;int&gt;(1024, gpuQueue));
  
<mark>auto e1 = gpuQueue.memcpy(devicePtr, data, sizeof(int));</mark>
  
auto e2 = gpuQueue.parallel_for&lt;kernel_a&gt;(
  sycl::range{1024}, e1, [=](sycl::id&lt;1&gt; idx){
    devicePtr[idx] = /* some computation */
});

auto e3 = gpuQueue.parallel_for&lt;kernel_b&gt;(
  sycl::range{1024}, e2, [=](sycl::id&lt;1&gt; idx){
    devicePtr[idx] = /* some computation */
});

auto e4 = gpuQueue.memcpy(data, devicePtr, sizeof(int),
  e3);

e4.wait();
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* The `memcpy` member functions are used to enqueue data movement commands, moving the data to the GPU and then back again.
						</div>
					</div>
				</section>
				<!--Slide 14-->
				<section>
					<div class="hbox" data-markdown>
						#### Concurrent data flow
					</div>
					<div class="container">
						<div class="col" data-markdown>
							![SYCL](./concurrent_data_flow.png "SYCL")
						</div>
						<div class="col" data-markdown>
							* If two kernels are accessing different buffers then there is no dependency between them.
							* In this case the two kernels and their respective data movement are independent.
							* By default `queue`s are out-of-order which means that these commands can execute in any order.
							* They could also execute concurrently if the target device is able to do so.
						</div>
					</div>
				</section>
				<!--Slide 15-->
				<section>
					<div class="hbox" data-markdown>
						#### Concurrent data flow with buffers and accessors
					</div>
					<div class="container">
						<div class="col">
							<code class="code-100pc"><pre>
bufA = sycl::buffer(dataA, sycl::range{1024});
bufB = sycl::buffer(dataB, sycl::range{1024}); 

gpuQueue.submit([&](sycl::handler &cgh){
  <mark>auto accA = bufA.get_access(cgh);</mark>
      
  cgh.parallel_for&lt;kernel_a&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
      accB[idx] = /* some computation */
  });
});

gpuQueue.submit([&](sycl::handler &cgh){
  <mark>auto accB = bufB.get_access(cgh);</mark>
  
  cgh.parallel_for&lt;kernel_b&gt;(sycl::range{1024},
    [=](sycl::id&lt;1&gt; idx){
      accB[idx] = /* some computation */
  });
});

gpuQueue.wait();
							</code></pre>
						</div>
						<div class="col" data-markdown>
							* The buffer/accessor data management model automatically infers dependencies.
							* As each of the two kernel functions are accessing different `buffer` objects the SYCL runtime can infer there is no dependency between them.
							* Data movement is still performed for the two kernels as normal.
							* The two kernels and their respective copies collectively can be executed in any order.
						</div>
					</div>
				</section>
				<!--Slide 16-->
				<section>
					<div class="hbox" data-markdown>
						#### Concurrent data flow with USM
					</div>
					<div class="container">
						<code class="code-100pc"><pre>
auto devicePtrA = usm_wrapper&lt;int&gt;(malloc_device&lt;int&gt;(1024, gpuQueue));
auto devicePtrB = usm_wrapper&lt;int&gt;(malloc_device&lt;int&gt;(1024, gpuQueue));
  
<mark>auto e1</mark> = gpuQueue.memcpy(devicePtrA, dataA, sizeof(int));
auto e2 = gpuQueue.memcpy(devicePtrB, dataB, sizeof(int));
  
<mark>auto e3</mark> = gpuQueue.parallel_for&lt;kernel_a&gt;(sycl::range{1024}, <mark>e1</mark>, [=](sycl::id&lt;1&gt; idx){
  devicePtr[idx] = /* some computation */ });

auto e4 = gpuQueue.parallel_for&lt;kernel_b&gt;(sycl::range{1024}, e2, [=](sycl::id&lt;1&gt; idx){
  devicePtr[idx] = /* some computation */ });

<mark>auto e5</mark> = gpuQueue.memcpy(dataA), devicePtrA, sizeof(int), <mark>e3</mark>);

auto e6 = gpuQueue.memcpy(dataB, devicePtrB, sizeof(int), e4);

<mark>e5.wait();</mark> e6.wait();
							</code></pre>
					</div>
					<div class="container" data-markdown>
						* Dependencies are defined explicitly.
						* We don't create dependencies between kernel functions but we do create dependencies on the data movement.
					</div>
				</section>
				<!--Slide 17-->
				<section>
					<div class="hbox" data-markdown>
						#### Concurrent data flow with USM
					</div>
					<div class="container">
						<code class="code-100pc"><pre>
auto devicePtrA = usm_wrapper&lt;int&gt;(malloc_device&lt;int&gt;(1024, gpuQueue));
auto devicePtrB = usm_wrapper&lt;int&gt;(malloc_device&lt;int&gt;(1024, gpuQueue));
  
auto e1 = gpuQueue.memcpy(devicePtrA, dataA, sizeof(int));
<mark>auto e2</mark> = gpuQueue.memcpy(devicePtrB, dataB, sizeof(int));
  
auto e3 = gpuQueue.parallel_for&lt;kernel_a&gt;(sycl::range{1024}, e1, [=](sycl::id&lt;1&gt; idx){
  devicePtr[idx] = /* some computation */ });

<mark>auto e4</mark> = gpuQueue.parallel_for&lt;kernel_b&gt;(sycl::range{1024}, <mark>e2</mark>, [=](sycl::id&lt;1&gt; idx){
  devicePtr[idx] = /* some computation */ });

auto e5 = gpuQueue.memcpy(dataA), devicePtrA, sizeof(int), e3);

<mark>auto e6</mark> = gpuQueue.memcpy(dataB, devicePtrB, sizeof(int), <mark>e4</mark>);

e5.wait(); <mark>e6.wait();</mark>
							</code></pre>
					</div>
					<div class="container" data-markdown>
						* The dependencies of each chain of commands is independant of the other.
						* The two kernels and their respective copies collectively can be executed in any order.
					</div>
				</section>
				<!--Slide 15-->
				<section>
					<div class="hbox" data-markdown>
						#### Which should you choose?
					</div>
					<div class="container" data-markdown>
						When should you use the buffer/accessor or USM data management models?
					</div>
					<div class="container">
						<div class="col" data-markdown>
							Buffer/accessor data movement model
							<br/>
							* If you want to guarantee consistency and avoid errors.
							* If you want to iterate over your data flow quicker.
						</div>
						<div class="col" data-markdown>
							USM data movement model
							<br/>
							* If you need to use USM.
							* If you want more fine grained control over data movement.
						</div>
					</div>
				</section>
				<!--Slide 16-->
				<section>
					<div class="hbox" data-markdown>
						## Questions
					</div>
				</section>
				<!--Slide 17-->
				<section>
					<div class="hbox" data-markdown>
						#### Exercise
					</div>
					<div class="container" data-markdown>
						Code_Exercises/Exercise_10_Managing_Dependencies/source
					</div>
					<div class="container" data-markdown>
						![SYCL](./diamond_data_flow.png "SYCL")
					</div>
					<div class="container" data-markdown>
						Put together what you've seen here to create the above diamond data flow graph in either buffer/accessor or USM data management models.
					</div>
				</section>
			</div>
		</div>
		<script src="../common-revealjs/js/reveal.js"></script>
		<script src="../common-revealjs/plugin/markdown/marked.js"></script>
		<script src="../common-revealjs/plugin/markdown/markdown.js"></script>
		<script src="../common-revealjs/plugin/notes/notes.js"></script>
		<script>
			Reveal.initialize({mouseWheel: true, defaultNotes: true});
			Reveal.configure({ slideNumber: true });
		</script>
	</body>
</html>
